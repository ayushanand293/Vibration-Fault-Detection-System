{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612c23d8-1ecf-42e9-9879-571483e5a278",
   "metadata": {},
   "source": [
    "# PART B: Machine Learning Fault Classification\n",
    "## Vibration-Based Bearing Fault Detection System\n",
    "\n",
    "**Author:** Ayush Anand  \n",
    "**Date:** November 2024  \n",
    "**Dataset:** CWRU Bearing Features (from Part A)\n",
    "\n",
    "---\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook implements machine learning models to automatically classify bearing faults based on vibration signal features.\n",
    "\n",
    "### Objectives:\n",
    "1. ‚úÖ Prepare dataset with extracted features\n",
    "2. ‚úÖ Train **Random Forest** classifier\n",
    "3. ‚úÖ Train **MLP Neural Network** classifier\n",
    "4. ‚úÖ Compare model performance\n",
    "5. ‚úÖ Evaluate using multiple metrics\n",
    "\n",
    "### Models:\n",
    "- **Random Forest** - Ensemble decision tree classifier\n",
    "- **MLP (Multi-Layer Perceptron)** - Neural network classifier\n",
    "\n",
    "### Evaluation Metrics:\n",
    "- Accuracy, Precision, Recall, F1-Score\n",
    "- Confusion Matrices\n",
    "- ROC Curves & AUC\n",
    "- Feature Importance Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dc31bb-911f-45f7-884e-b8defa163c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚úÖ LIBRARIES IMPORTED SUCCESSFULLY\n",
      "======================================================================\n",
      "üì¶ NumPy version: 2.3.5\n",
      "üì¶ Pandas version: 2.3.3\n",
      "üì¶ Scikit-learn ready\n",
      "üì¶ Matplotlib ready\n",
      "‚è∞ Timestamp: 2025-11-30 11:59:07\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, \n",
    "    roc_curve, auc, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Configure\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('../reports', exist_ok=True)\n",
    "\n",
    "print('='*70)\n",
    "print('‚úÖ LIBRARIES IMPORTED SUCCESSFULLY')\n",
    "print('='*70)\n",
    "print(f'üì¶ NumPy version: {np.__version__}')\n",
    "print(f'üì¶ Pandas version: {pd.__version__}')\n",
    "print(f'üì¶ Scikit-learn ready')\n",
    "print(f'üì¶ Matplotlib ready')\n",
    "print(f'‚è∞ Timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "print('='*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a476550-3cec-4786-a152-e9eeaf5c2cb8",
   "metadata": {},
   "source": [
    "---\n",
    "## 1Ô∏è‚É£ Dataset Preparation\n",
    "\n",
    "We load the feature dataset created in Part A, which contains 14 engineered features extracted from vibration signals.\n",
    "\n",
    "### Features Include:\n",
    "- **Time-Domain (6):** RMS, Peak, Crest Factor, Kurtosis, Skewness, Std Dev\n",
    "- **Frequency-Domain (8):** Dominant Frequency, Peak FFT Magnitude, Top 3 Frequencies, Spectral Entropy, Frequency Centroid\n",
    "\n",
    "### Classes:\n",
    "- **Normal** - Healthy bearing\n",
    "- **Inner Race** - Inner race fault\n",
    "- **Outer Race** - Outer race fault  \n",
    "- **Ball** - Ball bearing fault\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9ac2b3-3c7d-4d64-baa0-967c8c41d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATASET\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Dataset loaded successfully!\n",
      "üìä Dataset shape: (4, 15)\n",
      "üìã Number of features: 14\n",
      "üè∑Ô∏è  Number of classes: 4\n",
      "\n",
      "======================================================================\n",
      "CLASS DISTRIBUTION\n",
      "======================================================================\n",
      "  normal         :   1 samples (25.0%)\n",
      "  inner_race     :   1 samples (25.0%)\n",
      "  outer_race     :   1 samples (25.0%)\n",
      "  ball           :   1 samples (25.0%)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FEATURE COLUMNS\n",
      "======================================================================\n",
      "\n",
      "Time-Domain Features:\n",
      "  1. rms\n",
      "  2. peak\n",
      "  3. peak_to_peak\n",
      "  4. crest_factor\n",
      "  5. kurtosis\n",
      "  6. skewness\n",
      "  7. std_dev\n",
      "\n",
      "Frequency-Domain Features:\n",
      "  1. dominant_frequency\n",
      "  2. peak_fft_magnitude\n",
      "  3. top_freq_1\n",
      "  4. top_freq_2\n",
      "  5. top_freq_3\n",
      "  6. spectral_entropy\n",
      "  7. frequency_centroid\n",
      "======================================================================\n",
      "\n",
      "üìã Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rms</th>\n",
       "      <th>peak</th>\n",
       "      <th>peak_to_peak</th>\n",
       "      <th>crest_factor</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>skewness</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>dominant_frequency</th>\n",
       "      <th>peak_fft_magnitude</th>\n",
       "      <th>top_freq_1</th>\n",
       "      <th>top_freq_2</th>\n",
       "      <th>top_freq_3</th>\n",
       "      <th>spectral_entropy</th>\n",
       "      <th>frequency_centroid</th>\n",
       "      <th>fault_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.437762</td>\n",
       "      <td>4.867983</td>\n",
       "      <td>2.437762</td>\n",
       "      <td>-0.076018</td>\n",
       "      <td>-0.005374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1.321167</td>\n",
       "      <td>31.186708</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.556979</td>\n",
       "      <td>5.059222</td>\n",
       "      <td>2.556979</td>\n",
       "      <td>-0.061326</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>296.5</td>\n",
       "      <td>297.5</td>\n",
       "      <td>1.311411</td>\n",
       "      <td>299.266346</td>\n",
       "      <td>inner_race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.417903</td>\n",
       "      <td>4.809594</td>\n",
       "      <td>2.417903</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>249.5</td>\n",
       "      <td>250.5</td>\n",
       "      <td>1.268307</td>\n",
       "      <td>250.567150</td>\n",
       "      <td>outer_race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.515899</td>\n",
       "      <td>5.025675</td>\n",
       "      <td>2.515899</td>\n",
       "      <td>-0.071225</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>399.5</td>\n",
       "      <td>400.5</td>\n",
       "      <td>1.316902</td>\n",
       "      <td>401.860623</td>\n",
       "      <td>ball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rms      peak  peak_to_peak  crest_factor  kurtosis  skewness  std_dev  \\\n",
       "0  1.0  2.437762      4.867983      2.437762 -0.076018 -0.005374      1.0   \n",
       "1  1.0  2.556979      5.059222      2.556979 -0.061326 -0.007121      1.0   \n",
       "2  1.0  2.417903      4.809594      2.417903 -0.077072  0.002775      1.0   \n",
       "3  1.0  2.515899      5.025675      2.515899 -0.071225  0.000556      1.0   \n",
       "\n",
       "   dominant_frequency  peak_fft_magnitude  top_freq_1  top_freq_2  top_freq_3  \\\n",
       "0                30.0                 1.0        30.0        30.5        29.5   \n",
       "1               297.0                 1.0       297.0       296.5       297.5   \n",
       "2               250.0                 1.0       250.0       249.5       250.5   \n",
       "3               400.0                 1.0       400.0       399.5       400.5   \n",
       "\n",
       "   spectral_entropy  frequency_centroid  fault_type  \n",
       "0          1.321167           31.186708      normal  \n",
       "1          1.311411          299.266346  inner_race  \n",
       "2          1.268307          250.567150  outer_race  \n",
       "3          1.316902          401.860623        ball  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Statistical Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rms</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.648033e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.482136</td>\n",
       "      <td>6.541226e-02</td>\n",
       "      <td>2.417903</td>\n",
       "      <td>2.432798</td>\n",
       "      <td>2.476831</td>\n",
       "      <td>2.526169</td>\n",
       "      <td>2.556979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak_to_peak</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.940618</td>\n",
       "      <td>1.207540e-01</td>\n",
       "      <td>4.809594</td>\n",
       "      <td>4.853386</td>\n",
       "      <td>4.946829</td>\n",
       "      <td>5.034061</td>\n",
       "      <td>5.059222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crest_factor</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.482136</td>\n",
       "      <td>6.541226e-02</td>\n",
       "      <td>2.417903</td>\n",
       "      <td>2.432798</td>\n",
       "      <td>2.476831</td>\n",
       "      <td>2.526169</td>\n",
       "      <td>2.556979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.071410</td>\n",
       "      <td>7.188340e-03</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>-0.076281</td>\n",
       "      <td>-0.073621</td>\n",
       "      <td>-0.068750</td>\n",
       "      <td>-0.061326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.002291</td>\n",
       "      <td>4.711836e-03</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>-0.005810</td>\n",
       "      <td>-0.002409</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.002775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_dev</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.648033e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominant_frequency</th>\n",
       "      <td>4.0</td>\n",
       "      <td>244.250000</td>\n",
       "      <td>1.559666e+02</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>273.500000</td>\n",
       "      <td>322.750000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peak_fft_magnitude</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_freq_1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>244.250000</td>\n",
       "      <td>1.559666e+02</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>273.500000</td>\n",
       "      <td>322.750000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_freq_2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>1.555088e+02</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>194.750000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>322.250000</td>\n",
       "      <td>399.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_freq_3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>244.500000</td>\n",
       "      <td>1.564246e+02</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>195.250000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>323.250000</td>\n",
       "      <td>400.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectral_entropy</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.304447</td>\n",
       "      <td>2.442166e-02</td>\n",
       "      <td>1.268307</td>\n",
       "      <td>1.300635</td>\n",
       "      <td>1.314156</td>\n",
       "      <td>1.317968</td>\n",
       "      <td>1.321167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency_centroid</th>\n",
       "      <td>4.0</td>\n",
       "      <td>245.720207</td>\n",
       "      <td>1.563065e+02</td>\n",
       "      <td>31.186708</td>\n",
       "      <td>195.722039</td>\n",
       "      <td>274.916748</td>\n",
       "      <td>324.914915</td>\n",
       "      <td>401.860623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count        mean           std        min         25%  \\\n",
       "rms                   4.0    1.000000  1.648033e-10   1.000000    1.000000   \n",
       "peak                  4.0    2.482136  6.541226e-02   2.417903    2.432798   \n",
       "peak_to_peak          4.0    4.940618  1.207540e-01   4.809594    4.853386   \n",
       "crest_factor          4.0    2.482136  6.541226e-02   2.417903    2.432798   \n",
       "kurtosis              4.0   -0.071410  7.188340e-03  -0.077072   -0.076281   \n",
       "skewness              4.0   -0.002291  4.711836e-03  -0.007121   -0.005810   \n",
       "std_dev               4.0    1.000000  1.648033e-10   1.000000    1.000000   \n",
       "dominant_frequency    4.0  244.250000  1.559666e+02  30.000000  195.000000   \n",
       "peak_fft_magnitude    4.0    1.000000  0.000000e+00   1.000000    1.000000   \n",
       "top_freq_1            4.0  244.250000  1.559666e+02  30.000000  195.000000   \n",
       "top_freq_2            4.0  244.000000  1.555088e+02  30.500000  194.750000   \n",
       "top_freq_3            4.0  244.500000  1.564246e+02  29.500000  195.250000   \n",
       "spectral_entropy      4.0    1.304447  2.442166e-02   1.268307    1.300635   \n",
       "frequency_centroid    4.0  245.720207  1.563065e+02  31.186708  195.722039   \n",
       "\n",
       "                           50%         75%         max  \n",
       "rms                   1.000000    1.000000    1.000000  \n",
       "peak                  2.476831    2.526169    2.556979  \n",
       "peak_to_peak          4.946829    5.034061    5.059222  \n",
       "crest_factor          2.476831    2.526169    2.556979  \n",
       "kurtosis             -0.073621   -0.068750   -0.061326  \n",
       "skewness             -0.002409    0.001111    0.002775  \n",
       "std_dev               1.000000    1.000000    1.000000  \n",
       "dominant_frequency  273.500000  322.750000  400.000000  \n",
       "peak_fft_magnitude    1.000000    1.000000    1.000000  \n",
       "top_freq_1          273.500000  322.750000  400.000000  \n",
       "top_freq_2          273.000000  322.250000  399.500000  \n",
       "top_freq_3          274.000000  323.250000  400.500000  \n",
       "spectral_entropy      1.314156    1.317968    1.321167  \n",
       "frequency_centroid  274.916748  324.914915  401.860623  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load preprocessed features from Part A\n",
    "print('='*70)\n",
    "print('LOADING DATASET')\n",
    "print('='*70)\n",
    "\n",
    "df = pd.read_csv('data/cwru_features.csv')\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üìã Number of features: {df.shape[1] - 1}\")\n",
    "print(f\"üè∑Ô∏è  Number of classes: {df['fault_type'].nunique()}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print('CLASS DISTRIBUTION')\n",
    "print('='*70)\n",
    "class_counts = df['fault_type'].value_counts()\n",
    "for fault, count in class_counts.items():\n",
    "    print(f\"  {fault:15s}: {count:3d} samples ({count/len(df)*100:.1f}%)\")\n",
    "print('='*70)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print('FEATURE COLUMNS')\n",
    "print('='*70)\n",
    "print(\"\\nTime-Domain Features:\")\n",
    "time_features = ['rms', 'peak', 'crest_factor', 'kurtosis', 'skewness', 'std_dev', 'peak_to_peak']\n",
    "for idx, col in enumerate([c for c in df.columns if c in time_features], 1):\n",
    "    print(f\"  {idx}. {col}\")\n",
    "\n",
    "print(\"\\nFrequency-Domain Features:\")\n",
    "freq_features = ['dominant_frequency', 'peak_fft_magnitude', 'top_freq_1', 'top_freq_2', \n",
    "                 'top_freq_3', 'spectral_entropy', 'frequency_centroid']\n",
    "for idx, col in enumerate([c for c in df.columns if c in freq_features], 1):\n",
    "    print(f\"  {idx}. {col}\")\n",
    "print('='*70)\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìã Sample Data:\")\n",
    "display(df)\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nüìä Statistical Summary:\")\n",
    "display(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef47509-f6c4-417d-8ad0-54dc768515c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA PREPROCESSING & AUGMENTATION\n",
      "======================================================================\n",
      "\n",
      "‚ö†Ô∏è  Original dataset: 4 samples\n",
      "   ‚îî‚îÄ Too small for train-test split!\n",
      "\n",
      "üîÑ Generating synthetic samples using data augmentation...\n",
      "‚úÖ Augmented dataset: 100 samples\n",
      "   ‚îî‚îÄ 25 samples per class\n",
      "\n",
      "‚úÖ Features (X): (100, 14)\n",
      "‚úÖ Labels (y): (100,)\n",
      "\n",
      "======================================================================\n",
      "LABEL ENCODING\n",
      "======================================================================\n",
      "  ball            ‚Üí 0  (25 samples)\n",
      "  inner_race      ‚Üí 1  (25 samples)\n",
      "  normal          ‚Üí 2  (25 samples)\n",
      "  outer_race      ‚Üí 3  (25 samples)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TRAIN-TEST SPLIT (80%-20%)\n",
      "======================================================================\n",
      "üì¶ Training set:   80 samples (80.0%)\n",
      "üì¶ Testing set:    20 samples (20.0%)\n",
      "üìä Features:       14\n",
      "\n",
      "üîç Training set class distribution:\n",
      "   ball           : 20 samples\n",
      "   inner_race     : 20 samples\n",
      "   normal         : 20 samples\n",
      "   outer_race     : 20 samples\n",
      "\n",
      "üîç Testing set class distribution:\n",
      "   ball           : 5 samples\n",
      "   inner_race     : 5 samples\n",
      "   normal         : 5 samples\n",
      "   outer_race     : 5 samples\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Data preprocessing complete!\n",
      "‚úÖ Dataset augmented to 100 samples\n",
      "‚úÖ Ready for model training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('='*70)\n",
    "print('DATA PREPROCESSING & AUGMENTATION')\n",
    "print('='*70)\n",
    "\n",
    "# Check current data size\n",
    "print(f\"\\n‚ö†Ô∏è  Original dataset: {len(df)} samples\")\n",
    "print(f\"   ‚îî‚îÄ Too small for train-test split!\")\n",
    "\n",
    "# Separate features and target\n",
    "X_original = df.drop('fault_type', axis=1)\n",
    "y_original = df['fault_type']\n",
    "\n",
    "print(f\"\\nüîÑ Generating synthetic samples using data augmentation...\")\n",
    "\n",
    "# Generate more samples by adding small random noise\n",
    "np.random.seed(42)\n",
    "augmented_data = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    fault_type = row['fault_type']\n",
    "    features = row.drop('fault_type')\n",
    "    \n",
    "    # Keep original sample\n",
    "    augmented_data.append(row.to_dict())\n",
    "    \n",
    "    # Generate 24 more samples with small random variations\n",
    "    for i in range(24):\n",
    "        # Add Gaussian noise (5% of standard deviation)\n",
    "        noise = np.random.normal(0, 0.05, len(features))\n",
    "        augmented_features = features + noise\n",
    "        \n",
    "        # Create new sample\n",
    "        new_sample = augmented_features.to_dict()\n",
    "        new_sample['fault_type'] = fault_type\n",
    "        augmented_data.append(new_sample)\n",
    "\n",
    "# Create augmented dataframe\n",
    "df_augmented = pd.DataFrame(augmented_data)\n",
    "\n",
    "print(f\"‚úÖ Augmented dataset: {len(df_augmented)} samples\")\n",
    "print(f\"   ‚îî‚îÄ {len(df_augmented) // 4} samples per class\")\n",
    "\n",
    "# Now separate features and target from augmented data\n",
    "X = df_augmented.drop('fault_type', axis=1)\n",
    "y = df_augmented['fault_type']\n",
    "\n",
    "print(f\"\\n‚úÖ Features (X): {X.shape}\")\n",
    "print(f\"‚úÖ Labels (y): {y.shape}\")\n",
    "\n",
    "# Encode labels to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print('LABEL ENCODING')\n",
    "print('='*70)\n",
    "for idx, fault in enumerate(label_encoder.classes_):\n",
    "    count = np.sum(y_encoded == idx)\n",
    "    print(f\"  {fault:15s} ‚Üí {idx}  ({count} samples)\")\n",
    "print('='*70)\n",
    "\n",
    "# Now we can split: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.20, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print('TRAIN-TEST SPLIT (80%-20%)')\n",
    "print('='*70)\n",
    "print(f\"üì¶ Training set:   {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"üì¶ Testing set:    {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"üìä Features:       {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\nüîç Training set class distribution:\")\n",
    "for idx, fault in enumerate(label_encoder.classes_):\n",
    "    count = np.sum(y_train == idx)\n",
    "    print(f\"   {fault:15s}: {count} samples\")\n",
    "\n",
    "print(f\"\\nüîç Testing set class distribution:\")\n",
    "for idx, fault in enumerate(label_encoder.classes_):\n",
    "    count = np.sum(y_test == idx)\n",
    "    print(f\"   {fault:15s}: {count} samples\")\n",
    "\n",
    "print('='*70)\n",
    "\n",
    "# Feature names for later use\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(f\"\\n‚úÖ Data preprocessing complete!\")\n",
    "print(f\"‚úÖ Dataset augmented to {len(df_augmented)} samples\")\n",
    "print(f\"‚úÖ Ready for model training!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d500d3f-b6a5-4a15-94c5-26bc27346070",
   "metadata": {},
   "source": [
    "---\n",
    "## 2Ô∏è‚É£ Model Training\n",
    "\n",
    "### Random Forest Classifier\n",
    "\n",
    "**Algorithm:** Ensemble of decision trees  \n",
    "**Key Hyperparameters:**\n",
    "- `n_estimators=100` - Number of trees in the forest\n",
    "- `max_depth=10` - Maximum depth of each tree\n",
    "- `min_samples_split=2` - Minimum samples to split a node\n",
    "- `random_state=42` - For reproducibility\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ Handles non-linear relationships\n",
    "- ‚úÖ Robust to overfitting\n",
    "- ‚úÖ Provides feature importance\n",
    "- ‚úÖ Works well with small datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b972629-77f0-42e9-a0c2-f8bf72e70677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING RANDOM FOREST CLASSIFIER\n",
      "======================================================================\n",
      "\n",
      "üîÑ Training Random Forest...\n",
      "   ‚îî‚îÄ Building 100 decision trees...\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üîÑ Making predictions on test set...\n",
      "‚úÖ Predictions complete!\n",
      "\n",
      "======================================================================\n",
      "RANDOM FOREST PERFORMANCE\n",
      "======================================================================\n",
      "üéØ Accuracy:  100.00%\n",
      "üéØ Precision: 100.00%\n",
      "üéØ Recall:    100.00%\n",
      "üéØ F1-Score:  100.00%\n",
      "======================================================================\n",
      "\n",
      "üìä Detailed Classification Report:\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ball       1.00      1.00      1.00         5\n",
      "  inner_race       1.00      1.00      1.00         5\n",
      "      normal       1.00      1.00      1.00         5\n",
      "  outer_race       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üíæ Model saved: models/random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print('='*70)\n",
    "print('TRAINING RANDOM FOREST CLASSIFIER')\n",
    "print('='*70)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,        # 100 decision trees\n",
    "    max_depth=10,            # Maximum tree depth\n",
    "    min_samples_split=2,     # Minimum samples to split node\n",
    "    min_samples_leaf=1,      # Minimum samples in leaf\n",
    "    random_state=42,\n",
    "    n_jobs=-1,               # Use all CPU cores\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"\\nüîÑ Training Random Forest...\")\n",
    "print(\"   ‚îî‚îÄ Building 100 decision trees...\")\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Training complete!\\n\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"üîÑ Making predictions on test set...\")\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)\n",
    "print(\"‚úÖ Predictions complete!\\n\")\n",
    "\n",
    "# Evaluate\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "\n",
    "print('='*70)\n",
    "print('RANDOM FOREST PERFORMANCE')\n",
    "print('='*70)\n",
    "print(f\"üéØ Accuracy:  {accuracy_rf*100:.2f}%\")\n",
    "print(f\"üéØ Precision: {precision_rf*100:.2f}%\")\n",
    "print(f\"üéØ Recall:    {recall_rf*100:.2f}%\")\n",
    "print(f\"üéØ F1-Score:  {f1_rf*100:.2f}%\")\n",
    "print('='*70)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nüìä Detailed Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(\n",
    "    y_test, y_pred_rf, \n",
    "    target_names=label_encoder.classes_,\n",
    "    zero_division=0\n",
    "))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model\n",
    "with open('models/random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(\"\\nüíæ Model saved: models/random_forest_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9761b-e5f2-42d8-b969-d11a38345921",
   "metadata": {},
   "source": [
    "---\n",
    "## 3Ô∏è‚É£ MLP Neural Network Classifier\n",
    "\n",
    "**Algorithm:** Multi-Layer Perceptron (Feedforward Neural Network)  \n",
    "**Architecture:**\n",
    "- **Input Layer:** 14 neurons (one per feature)\n",
    "- **Hidden Layer 1:** 64 neurons (ReLU activation)\n",
    "- **Hidden Layer 2:** 32 neurons (ReLU activation)\n",
    "- **Hidden Layer 3:** 16 neurons (ReLU activation)\n",
    "- **Output Layer:** 4 neurons (Softmax - one per class)\n",
    "\n",
    "**Training Parameters:**\n",
    "- `solver='adam'` - Adaptive learning rate optimizer\n",
    "- `learning_rate_init=0.001` - Initial learning rate\n",
    "- `max_iter=500` - Maximum epochs\n",
    "- `early_stopping=True` - Stop if validation loss doesn't improve\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ Learns complex non-linear patterns\n",
    "- ‚úÖ Deep learning architecture\n",
    "- ‚úÖ Adaptive learning rate\n",
    "- ‚úÖ Early stopping prevents overfitting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c4ffe1-2cb1-419b-934d-5fa510a8f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING MLP NEURAL NETWORK\n",
      "======================================================================\n",
      "\n",
      "üîÑ Training MLP Neural Network...\n",
      "   ‚îú‚îÄ Architecture: Input(14) ‚Üí Hidden(64,32,16) ‚Üí Output(4)\n",
      "   ‚îú‚îÄ Activation: ReLU\n",
      "   ‚îú‚îÄ Optimizer: Adam\n",
      "   ‚îî‚îÄ Early stopping enabled\n",
      "\n",
      "‚úÖ Training complete!\n",
      "   ‚îî‚îÄ Converged in 14 iterations\n",
      "\n",
      "üîÑ Making predictions on test set...\n",
      "‚úÖ Predictions complete!\n",
      "\n",
      "======================================================================\n",
      "MLP NEURAL NETWORK PERFORMANCE\n",
      "======================================================================\n",
      "üéØ Accuracy:  25.00%\n",
      "üéØ Precision: 6.25%\n",
      "üéØ Recall:    25.00%\n",
      "üéØ F1-Score:  10.00%\n",
      "======================================================================\n",
      "\n",
      "üìä Detailed Classification Report:\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ball       0.00      0.00      0.00         5\n",
      "  inner_race       0.25      1.00      0.40         5\n",
      "      normal       0.00      0.00      0.00         5\n",
      "  outer_race       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.25        20\n",
      "   macro avg       0.06      0.25      0.10        20\n",
      "weighted avg       0.06      0.25      0.10        20\n",
      "\n",
      "======================================================================\n",
      "\n",
      "üíæ Model saved: models/mlp_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print('='*70)\n",
    "print('TRAINING MLP NEURAL NETWORK')\n",
    "print('='*70)\n",
    "\n",
    "# Initialize MLP\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32, 16),  # 3 hidden layers\n",
    "    activation='relu',                 # ReLU activation\n",
    "    solver='adam',                     # Adam optimizer\n",
    "    learning_rate_init=0.001,          # Learning rate\n",
    "    max_iter=500,                      # Maximum epochs\n",
    "    random_state=42,\n",
    "    early_stopping=True,               # Stop if no improvement\n",
    "    validation_fraction=0.2,           # 20% for validation\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\nüîÑ Training MLP Neural Network...\")\n",
    "print(\"   ‚îú‚îÄ Architecture: Input(14) ‚Üí Hidden(64,32,16) ‚Üí Output(4)\")\n",
    "print(\"   ‚îú‚îÄ Activation: ReLU\")\n",
    "print(\"   ‚îú‚îÄ Optimizer: Adam\")\n",
    "print(\"   ‚îî‚îÄ Early stopping enabled\")\n",
    "\n",
    "# Train the model\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete!\")\n",
    "print(f\"   ‚îî‚îÄ Converged in {mlp_model.n_iter_} iterations\\n\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"üîÑ Making predictions on test set...\")\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "y_pred_proba_mlp = mlp_model.predict_proba(X_test)\n",
    "print(\"‚úÖ Predictions complete!\\n\")\n",
    "\n",
    "# Evaluate\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "precision_mlp = precision_score(y_test, y_pred_mlp, average='weighted', zero_division=0)\n",
    "recall_mlp = recall_score(y_test, y_pred_mlp, average='weighted', zero_division=0)\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp, average='weighted', zero_division=0)\n",
    "\n",
    "print('='*70)\n",
    "print('MLP NEURAL NETWORK PERFORMANCE')\n",
    "print('='*70)\n",
    "print(f\"üéØ Accuracy:  {accuracy_mlp*100:.2f}%\")\n",
    "print(f\"üéØ Precision: {precision_mlp*100:.2f}%\")\n",
    "print(f\"üéØ Recall:    {recall_mlp*100:.2f}%\")\n",
    "print(f\"üéØ F1-Score:  {f1_mlp*100:.2f}%\")\n",
    "print('='*70)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nüìä Detailed Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(\n",
    "    y_test, y_pred_mlp, \n",
    "    target_names=label_encoder.classes_,\n",
    "    zero_division=0\n",
    "))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save model\n",
    "with open('models/mlp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(mlp_model, f)\n",
    "print(\"\\nüíæ Model saved: models/mlp_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da9a15-9869-405c-8ac7-171c9abf10da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
